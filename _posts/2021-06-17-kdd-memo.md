---
layout: post
title: "KDD 2021 Memo"
tags: [KDD21]
---

<!--more-->

国際会議KDD2021の事前準備メモ

[Accepted Papers](https://kdd.org/kdd2021/accepted-papers/index)


## Research Track Papers

### A Graph-based Approach for Trajectory Similarity Computation in Spatial Networks
#### Peng Han (KAUST); Jin Wang (UCLA); Di Yao (Institute of Computing Technology, Chinese Academy of Sciences); Shuo Shang (KAUST); Xiangliang Zhang (King Abdullah University of Science and Technology, Saudi Arabia)  


### Accurate Multivariate Stock Movement Prediction via Data-Axis Transformer with Multi-Level Contexts
#### Jaemin Yoo (Seoul National University); Yejun Soun (Seoul National University); Yong-chan Park (Seoul National University); U Kang (Seoul National University) 


### ACE-NODE: Attentive Co-Evolving Neural Ordinary Differential Equations  [PDF](https://arxiv.org/abs/2105.14953)
#### Sheo Yon Jhin (Yonsei University); Minju Jo (Yonsei University); TaeYong Kong (Yonsei University); Jinsung Jeon (Yonsei university); Noseong Park (Yonsei University, Korea)  


### Adaptive Transfer Learning on Graph Neural Networks
#### Xueting Han (Microsoft Research Asia); Zhenhuan Huang (Beihang University, Microsoft Research Asia); Jing Bai (Microsoft); Bang An (University of Maryland, College Park; Microsoft Research Asia)


### Apriori Convolutions for Highly Efficient and Accurate Time Series Classification
#### Angus Dempster (Monash University); Daniel F Schmidt (Monash University); Geoffrey I Webb (Monash) 


### Attentive Heterogeneous Graph Embedding for Job Mobility Prediction
#### Le Zhang (University of Science and Technology of China) et al. 


### Auditing for Diversity Using Representative Examples
#### Vijay Keswani (Yale University); L. Elisa Celis (Yale University)


### Causal models for Real Time Bidding with repeated user interactions  [PDF](https://hal.archives-ouvertes.fr/hal-02971865/document)
#### Martin Bompaire (Criteo); Benjamin Heymann (Criteo); Alexandre Gilotte (Criteo)


### Causal Understanding of Fake News Dissemination on Social Media  [PDF](http://www.cs.iit.edu/~kshu/files/kdd_causal.pdf)
#### Lu Cheng (Arizona State University); Ruocheng Guo (Arizona State University); Kai Shu (Illinois Institute of Technology); Huan Liu (Arizona State University)


### Choice Set Confounding in Discrete Choice  [PDF](https://arxiv.org/abs/2105.07959)
#### Kiran Tomlinson (Cornell University); Johan Ugander (Stanford University); Austin R Benson (Cornell University) 
**イントロ**
- 個人の選択は環境政策, マーケティング, ウェブ検索, 推薦システム等幅広い応用で重要
- 離散選択モデルは個人が選択集合の中から代替案を選択する事象を定式化するもの
- しかしこれらのモデルは選択集合の割り当てが推薦アルゴリズムで決まるという事実を考慮していない 
- この論文では, 個人の嗜好に依存して選択集合が割り当てられる問題を選択集合の交絡と呼ぶ
- 離散選択においてはおとり効果, 妥協効果などの知見が確認されているが, 選択集合の交絡によってそれらの真の効果を見誤る可能性がある
- 本研究では選択集合の交絡が問題になるケースを分析 
- また, 離散選択モデルの評価でよく使われる2つの交通データセットにおいて, 選択集合の交絡の存在を示す証拠を提示した 
- さらに選択集合の交絡に対処するため, 2つの因果モデルを構築した

**背景技術**
- ここではそれぞれの離散選択が行われる確率を考え, その確率を最大にするようなパラメ-タを最尤法で推定する離散選択モデルを考える 
- 選択集合 $$C$$と選択 $$i$$のペア $$(C,u)$$の収集データ $$D$$が与えられた下で個人 (選択者) $$a$$が選択集合 $$C$$から要素 $$i$$を選ぶ確率を $$P(i\vert a,C)$$でモデル化
- 確率分布関数 $$P(\cdot)$$は一般的に選択集合 $$C$$の中の要素 $$i$$の効用 $$u_i(C,a)$$を用いてソフトマックス関数 $$Pr(i\vert a,C)=\exp{(u_i(C,a))}/\sum_j\exp{(u_j(C,a))}$$でモデル化される  
- $$u_i(C,a)=u_i$$とした場合, これはシンプルなロジットモデルに一致する
- 他にも個人の特徴量 $${\bf x}_{\bf a}$$, 要素 $$i$$の特徴量 $${\bf y}_i$$が観測できるケースもある 
- その場合, 効用 $$u_i(C,a)$$を $${\bf x}_{\bf a}$$, $${\bf y}_i$$を用いた形 (表1参照)で記述することでこれらの特徴量を考慮することができる
- これらの定式化は選択集合と要素が独立であるという IIAの仮定に基づいている
- $$u_i(C,a)$$をモデル化する際, 要素 $$i$$だけでなく選択集合 $$C$$の情報も使うアプローチが提案されている (表2)

**提案手法**
- 本論文では因果推論におけるIPWのアイデアを離散選択モデルに導入する
  - IPWは個々の共変量が与えられた場合の各治療割り当ての確率を記述した傾向スコアを推定するもの
  - 真の確率 $$Pr(T_i\vert X_i)$$は未知なので, 代わりに「傾向スコア」 $$\hat{Pr}(T_i\vert X_i)$を観測データから学習する
  - 通常ロジスティック回帰が用いられる
  - 傾向スコアは平均的な治療効果の推定や学習データの重み付けに使われる (今回は後者)
  - 各サンプルを各々の傾向スコアの逆数で重み付けすることで, 治療が共変量と関係なくランダムに割り当てられた擬似的な場合のデータを構築できる
- 偏りのない離散選択モデルを学習するためには, 選択者に依存しない選択集合が必要 
  - そのため, IPWを用いて擬似データセットを作成し, その擬似データセットを用いて離散選択モデルの学習を行う
  - そのために 選択セットの割り当て確率 $$Pr(C\vert a)$$をモデル化
  - そして, 各サンプル $$(i,a,C)$$を $$1/[\vert C_{\mathcal{D}}\vert Pr(C\vert a)]$$で置き換えることで擬似データセット $$\tilde{\mathcal{D}}$$を作成する
  - これは単純に尤度に重み $$1/C_{\mathcal{D}Pr(C\vert {\bf x}_a)$$を掛け合わせることに等しい
  - 今回は $$Pr(C\vert a)$$の代わりに $$Pr(C\vert {\bf x}_a)$$を使う 
    - そのために必要な仮定を図1に示す


### Context-aware Outstanding Fact Mining from Knowledge Graphs
#### Yueji Yang (National University of Singapore); Yuchen Li (Singapore Management University); Panagiotis Karras (Aarhus University); Anthony Tung (NUS) 


### Coupled Graph ODE for Learning Interacting System Dynamics
#### Zijie Huang (University of California, Los Angeles); Yizhou Sun (UCLA); Wei Wang (UCLA) 


### Deep Learning Embeddings for Data Series Similarity Search
#### Qitong Wang (University of Paris); Themis Palpanas (University of Paris)


### Differentiable Pattern Set Mining  [PDF](https://eda.mmci.uni-saarland.de/pubs/2021/binaps-fischer,vreeken.pdf)
#### Jonas Fischer (Max Planck Institute for Informatics); Jilles Vreeken (CISPA Helmholtz Center for Information Security)
**イントロ**
- 頻出パターンマイニングに取り組む
- パターンマイニングはある制約を満たすパターンでデータ中に高頻度に存在するものを全て列挙する 
- ユーザによって定義された"おもしろさ"の閾値を超えるパターンを制限なく列挙するため, 膨大なパターンを出力してしまいがち
- 最近, パターンマイニングをモデル選択問題として再定式化し, 代表的なパターンの組を明示的に求めるアプローチが提案されている
  - パターンの組の探索空間はパターン単体の探索空間よりもさらに大きく (特徴量次元の二重指数), 効率的な探索が難しい
  - 既存手法はいずれもヒューリスティックな手法に頼っており, せいぜい数百程度の特徴量を持つデータにしか適用できない
  - 全ゲノム関連研究 (GWAS), 数十万の特徴量からなる単一細胞系列のような最新の生物学的応用には適用できない
- 本研究では, これらの組み合わせに基づくアプローチの代わりに, 微分を用いたアプローチを提案する
- そのため, バイナリデータのための解釈可能なオートエンコーダ BinaPs (Binary Pattern Networks)を提案
  - BinaPsはエンコーダ (隠れ層)とデコーダ (出力層)の2つの線形層から構成されている
  - エンコーダとデコーダで重みを共有
  - 学習時は通常通り連続値の重み $$W$$を使用
  - フォワードパスにおいては $$W$$を離散化 (バイナリ化)した重み $$W_b$$を使用
  - こうしておくと, $$W_b$$が共起関係を表す行列になっている
<img src="../../../assets/images/BinaPs.png" width="350px"> 
<figcaption>元論文図1より引用</figcaption>
- 本研究では, データの疎性を考慮した再構成損失を提案している
- 提案手法は密度の高い生物学的データにも疎な金融取引データにも適用可能



### Discrete Choice Models with Interpretable Context Effects
#### Kiran Tomlinson (Cornell University); Austin R Benson (Cornell University)


### Efficient Data-specific Model Search for Collaborative Filtering  [PDF](https://arxiv.org/abs/2106.07453)
#### Chen Gao (Tsinghua University); Quanming Yao (4Paradigm); Depeng Jin (Tsinghua University); Yong Li (Tsinghua University)
**イントロ**
- 強調フィルタリングのベンチマークデータは様々な応用から生じるもので, 形態, 規模, 分布などが様々
  - 暗黙的なものと明示的なものの2つの代表的な形式がある
  - データセットの規模 (大きいか小さいか)や分布 (密か疎か)も多様 
- 素朴なMFやFISMに代表される行列分解は, 学習は容易だが表現力が限られているため, 複雑なユーザ・アイテム間の相互作用を捉えることができない
- 一方, ニューラルモデルは, データが十分な場合には優れた性能を発揮するが, 比較的小さいデータセットの場合にはうまくいかない
- この研究ではAutoMLを使ってCFモデルの探索を行うアプローチを提案する
- その際, (i) 適切な探索空間の設計 (ii) 効率的な探索を行う必要がある (データの性質が多様なため)

**提案手法**
- CFの重要な構成要素はユーザ・アイテム間の相互作用の評価
  - この論文では相互作用関数を探索するone-shotアルゴリズムであるSIFをCFタスクに一般化 
- 入力, エンコード, 表現学習, 相互作用の評価, 予測という5つのステージ各々で選択肢を設定する (表2参照)
  - 例えば入力としてはユーザID $$\texttt{ID}$$, 過去の履歴 $$\texttt{History}$$を用意
  - 相互作用の評価関数として $$\texttt{multiply}$$, $$\texttt{min}$$, $$\texttt{max}$$, $$\texttt{concat}$$を用意 
- 埋め込みの次元, 学習率についても選択肢を用意しこれらも自動で学習する 
- さらに効率的な探索を行うため, ランダムサーチとperformance predictorを組み合わせた探索アルゴリズムを構築


### Energy-Efficient Models for High-Dimensional Spike Train Classification using Sparse Spiking Neural Networks  [PDF](https://thartvigsen.github.io/papers/kdd21.pdf)
#### Hang Yin (Worcestor Polytechnic Institute); John Lee (WPI); Xiangnan Kong (Worcester Polytechnic Institute); Thomas Hartvigsen (Worcester Polytechnic Institute); Sihong Xie (Lehigh University)


### Exploring Self-Supervised Representation Ensembles for COVID-19 Cough Classification  [PDF](https://arxiv.org/abs/2105.07566)
#### Hao Xue (RMIT University); Flora D. Salim (RMIT University)
**イントロ**
- 咳はCOVID-19患者の主要な症状の1つ
- COVID-19の診断のために呼吸音を自動的に分類するタスクに取り組む 
  - 咳の音による診断はスマホアプリ等でできるので, PCR検査や画像診断に比べて比較的手軽
- パンデミック時は, 健康なグループとCOVID-19陽性グループの両方から呼吸音を収集するため, 多くのクラウドソーシングプラットフォームが設計された
- これらのデータセットを用いてCOVID-19の検出を目的とした咳分類モデルが提案されている
- これらの手法は全て教師あり学習
  - データのアノテーションにはコストがかかる, プライバシーの問題が発生する
- 本研究では咳分類の教師なしモデルを提案する
- 提案手法は(i) 事前学習と(ii) 分類の二つのフェーズからなる 
  - 事前学習フェーズではラベルなしデータを用いてオートエンコーダを学習
  - その後の分類フェーズではオートエンコーダの学習パラメータを転用し, ラベル付きデータでファインチューニングする
- 音データの前処理にはTransformerを使う
  - ラベルなしデータとラベル付きデータの間での属性の偏りを考え, ランダムマスクの機構を用いる  


### Geometric Graph Representation Learning on Protein Structure Prediction
#### Tian Xia (Auburn University); Wei-Shinn Ku (Auburn University)


### Identifying Coordinated Accounts on Social Media through Hidden Influence and Group Behaviours  [PDF](https://arxiv.org/abs/2008.11308)
#### Karishma Sharma (University of Southern California); yizhou zhang (University of Southern California); Emilio Ferrara (University of Southern California, USA); Yan Liu (USC) 

### Interpreting Internal Activation Patterns in Deep Temporal Neural Networks by Finding Prototypes
#### Sohee Cho (KAIST); Wonjoon Chang (KAIST); GINKYENG LEE (UNIST-SAIL); Jaesik Choi (KAIST)

### JOHAN: A Joint Online Hurricane Trajectory and Intensity Forecasting Framework
#### Ding Wang (Michigan State University); Pang-Ning Tan (MSU)

### Knowledge is Power: Hierarchical-Knowledge Embedded Meta-Learning for Visual Reasoning in Artistic Domains
#### Wenbo Zheng (Xi'an Jiaotong University); Lan Yan (Chinese Academy of Sciences); Chao Gou (Sun Yat-Sen University); Feiyue Wang (Chinese Academy of Sciences)

### LawyerPAN: A Proficiency Assessment Network for Trial Lawyers
#### Yanqing An (University of Science and Technology of China) et al. 


### Learning Process-consistent Knowledge Tracing
#### Shuanghong Shen (University of Science and Technology of China) et al. 


### Learning to Recommend Visualizations from Data  [PDF](https://arxiv.org/abs/2009.12316)
#### Xin Qian (University of Maryland, College Park) et al. 

### MapRec: Map-Constrained Trajectory Recovery via Seq2Seq Multi-task Learning
#### Huimin Ren (Worcester Polytechnic Institute)

### Mitigating Performance Saturation in Neural Marked Point Processes: Architectures and Loss Functions
#### Tianbo Li (Nanyang Technological University); Tianze Luo (Nanyang Technological University); Yiping Ke (Nanyang Technological University); Sinno Pan (NTU, Singapore)


### Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System  [PDF](https://arxiv.org/abs/2010.15363)
#### Tianxin Wei (University of Science and Technology of China) et al. 

### Model-Based Counterfactual Synthesizer for Interpretation
#### Fan Yang (Texas A&M University); Sahan Alva (Texas A&M University); Jiahao Chen (JPMorgan AI Research); Xia Hu (Texas A&M University)

### Modeling Context-aware Features for Cognitive Diagnosis in Student Learning
#### Yuqiang Zhou (University of Science and Technology of China) et al. 

### MULTIVERSE: Mining Collective Data Science Knowledge from Code on the Web to Suggest Alternative Analysis Approaches
#### Mike A Merrill (University of Washington); Ge Zhang (Peking University); Tim Althoff (University of Washington)

### Neural-Answering Logical Queries on Knowledge Graphs
#### Lihui Liu (University of Illinois at Urbana-Champaign) et al. 

### NewsEmbed: Modeling News through Pre-trained Document Representations  [PDF](https://arxiv.org/abs/2106.00590)
#### Tianqi Liu (Google); Jialu Liu (Google Research); Cong Yu (Google)

### Physical Equation Discovery Using Physics-Consistent Neural Network (PCNN) Under Incomplete Observability
#### Haoran Li (Arizona State University); Yang Weng (Arizona State University)

### Popularity Bias in Dynamic Recommendation  [PDF](http://people.tamu.edu/~zhuziwei/pubs/Ziwei_KDD_2021.pdf)
#### Ziwei Zhu (Texas A&M University); Yun He (Texas A&M University); Xing Zhao (Texas A&M University); James Caverlee (Texas A&M University)


### PURE: Positive-Unlabeled Recommendation with Generative Adversarial Network
#### Yao Zhou (University of Illinois at Urbana-Champaign) et al. 

### Socially-Aware Self-Supervised Tri-Training for Recommendation  [PDF](https://arxiv.org/abs/2106.03569)
#### Junliang Yu (University of Queesland) et al. 

### Spatial-Temporal Graph ODE Networks for Traffic Flow Forecasting
#### Zheng Fang (pku); Qingqing Long (Peking University); Guojie Song (Peking University); Kunqing Xie (PKU)

### Table2Charts: Recommending Charts by Learning Shared Table Representations  [PDF](https://arxiv.org/abs/2008.11015)
#### Mengyu Zhou (Microsoft Research)
**イントロ**
- 表で表された多次元データからのチャートの作成は教育, 研究, エンジニアリング, 金融など様々な分野で一般的に行われている 
- その際, まずどのデータを使うかを選び (データの照合), その後どう可視化するか (デザインの選択)を決める
- チャートの作成にはデータ分析と可視化ツールに関する経験・知識が必要
- チャートの作成を自動化する手法はいくつかある
  - これらの手法はよく使われるチャートの種類 (折れ線グラフ, 棒グラフ, 散布図)をランク付けして推薦するもの (マルチタイプタスク)
  - あまり使われているわけではないが意味があるチャートの種類 (レーダーチャートなど)を1つ推薦するタスク (シングルタイプタスク)には適用できない
- シングルタイプ, マルチタイプの2つのタスクにおいてデータの照会とデザインの選択の両方を行う場合, 以下の3つの課題がある
  1. マルチタイプのタスクとシングルタイプのタスクのモデルを繰り返し独立して設計・学習・利用することは, メモリとスピードの両面で非効率
  2. データが不均衡. 4つの主要なチャートの種類 (折れ線グラフ, 棒グラフ, 散布図, 円グラフ)がデータの98.91%を占めているが, それ以外のマイナーなチャート (エリアやレーダー)のデータが少ない
  3. 表からデータを選択して視覚化する際, データの統計値だけでなく表全体の意味を考慮する必要がある
- 本論文では, 表・チャートのペアからなる大規模データからデータクエリとデザイン選択の両方を含むチャート作成の共通パターンを学習し, 与えられた表ごとにチャートを推薦するTable2Chartsフレームワークを提案
- Web上のデータから165214個の表から作成された266252個のチャートをエクセルファイルで収集
- この大規模コーパスを用いてTable2Chartの有効性を検証
  - 各チャートの種類について, シングルタイプ・マルチタイプのタスクにおけるトップ3およびトップ1推薦の精度を評価
- また, 検索数の多い500のWebテーブルを対象に人手による評価を行い提案手法の精度を検証
- 最後にT-SNEによる可視化を行なった
  - DQNがマルチタイプタスクの学習中に共有テーブル表現を学習し, 後の伝達学習に役立てることで, シングルタイプタスクの性能を向上させ, メモリ使用量を節約できることを示した


### TabularNet: A Neural Network Architecture for Understanding Semantic Structures of Tabular Data  [PDF](https://arxiv.org/abs/2106.03096) 
#### Lun Du (Microsoft Research) et al. 
**イントロ**
- 人にとって理解しやすく可視化された表をシンプルな表に変換
- このタスクはヘッダー領域の検出, セルの役割の分類という2つのサブタスクからなる
- 表形式のデータがどのように構成され, どのように相関しているかを深く理解するためには, 空間情報と関係情報を同時に考慮する必要がある
- 空間情報は統計的情報と領域間の差異の2種類ある
  - 同じ行や列のセルは意味的に一貫性があり, そこから平均値, 範囲, データタイプなどの統計情報を抽出することができる
  - また, ほとんどの表には, ヘッダ領域とデータ領域という2つの異なる領域がある
- 関係情報はセル間の階層的な関係や傍系的な関係など
- 本論文では, 表形式のデータの空間情報と関係情報を同時に捉えることができる新しいニューラルネット TabularNetを提案
- 表形式のデータを行列, グラフに変換し, それぞれに演算をかける
  - 行列表現から空間情報を抽出するため行/列レベルのPoolingとBi-GRUをかける
  - 表からグラフへの変換にはWordNetのグラフ構築アルゴリズムを適用
  - 階層的・傍系的な関係を学習するため, 構築したグラフにGCNをかける
- TabularNetの有効性を検証するため, 実世界の2つのスプレッドシートデータを用いて, セルの役割分類とヘッダの検出という2つの意味構造理解タスクを実施 
  - TabularNetはTransformerなど最新の既存手法を上回る精度 
  - マルチタスク設定においても有効


### TopNet: Learning from Neural Topic Model to Generate Long Stories
#### Yazheng Yang (Zhejiang University); Boyuan Pan (Zhejiang University); Deng Cai (Zhejiang University); Huan Sun (Ohio State University)


### Towards a Better Understanding of Linear Models for Recommendation  [PDF](https://arxiv.org/abs/2105.12937)
#### Ruoming Jin (Kent State University); Dong Li (Kent State University); Jing Gao (iLambda); Zhi Liu (iLambda); Li Chen (iLambda); Yang Zhou (Auburn University)
**イントロ**
- 推薦のための手法は回帰, 行列分解, 深層学習ベースのアプローチ等様々なものが提案されている 
- しかし, これらの手法はSLIMやEASEなどの線形モデルと比べて精度が出ないことが最近の研究でわかっている
- SLIM, EASEはユーザ-アイテム行列 $$X$$とアイテム同士の類似度行列 $$W$$の行列積 $$XW$$が $$X$$をうまく再現するような $$W$$を学習するもの
  - このモデルはシンプルな線形オートエンコーダと一致 (この時 $$W$$はエンコーダとデコーダを兼ねる)
  - $$W$$は行列分解のユーザベクトル, アイテムベクトルに比べて通常サイズが小さいため, 回帰モデルはあまり柔軟性がない
  - しかし, 直感に反して精度が出ている
  - これらのモデルを低ランク回帰モデルと呼ぶ
- この論文ではまず, こうした回帰モデルがなぜうまくいくか分析した
  - 2つのベーシックな低ランク回帰モデルと行列分解モデルを分析し, どちらの手法もユーザーアイテム相互作用行列の特異値をわずかに異なるメカニズムでスケールダウンしていることを明らかにした
  - 低ランク回帰は, 行列分解に比べて, ユーザーアイテム行列 $$X$$のより多くの主成分 (潜在的な次元)を利用できる
  - また, 行列分解法はユーザーとアイテムの両方の潜在因子行列を用いているためより多くのモデルパラメータを持っているように見えるが, 実際には単純な問題に対する最適解はアイテム行列にのみ依存していることがわかった 
- ユーザーとアイテムの相互作用行列の特異値をどのように調整できるかを理解するため, 高次元の連続的な (ハイパー)パラメータ空間を探索できる新しい学習アルゴリズムを導入した
  - 提案手法はモデルの学習後にも使うことができる
  - それによって, 線形モデルにパラメータを追加し, モデルの精度をさらに向上させることもできる
- このアプローチは筆者の最近の研究 (next-door analysis)と精神が似ているが, 適用先とアプローチが違う
- 本研究は推薦モデルのポストモデルフィッティング探索を対象とした初めての研究

**提案手法**
- 以下の低ランク回帰モデルを考える  
  $$W = \text{arg} \text{min}_{rank(W)\leq k}\vert\vert X-XW \vert\vert^2 + \vert\vert \Gamma W \vert\vert^2$$
  - $$\Gamma$$は $$W$$のフロベニウスノルムに対する制約を決める行列
- このモデルを回帰問題として捉え直す
  - この回帰問題はTikhonovの正則化と行列の低ランク近似という二つの部分問題に分けられる



### Where are we in embedding spaces? A Comprehensive Analysis on Network Embedding Approaches for Recommender Systems  [PDF](https://arxiv.org/abs/2105.08908)
#### Sixiao Zhang (University of Technology Sydney) et al. 
**イントロ**
- グラフベースの推薦システムでは, 行列分解に基づくモデルや計量学習に基づくモデルなどの潜在空間モデルが広く用いられている
- ほとんどの潜在空間モデルは, 直感的にわかりやすいユークリッド空間で構築されている
　- 従ってこれらのモデルはユークリッド空間の次元によって自由度が制限される
  - 特に階層的なデータを埋め込む際は歪みが問題になる
  - 歪みに対処するために高次元の潜在空間を考える必要がある
- 最近, 新しい潜在空間として双曲空間が検討されている
- 双曲空間の重要な特性は, ユークリッド空間よりも速く拡大する点
  - ユークリッド空間が多項式に従って拡大するのに対し, 双曲空間は指数関数的に拡大する
  - ユークリッド空間の円を考えると, 円の中心から離れたところにある多角形は中心に近いところにある多角形よりも小さくなる (図1a)
  - 一方, 双曲空間の円として扱うと, どのポリゴンも同じ大きさになる (図1b)
  - これは, 同じデータ群を埋め込むためにはユークリッド空間の方が双曲空間よりも必要な空間が大きいことを示唆している
- 双曲面空間のもう一つの重要な特性は, データの階層性を保持できること 
- 双曲面埋め込みは現在, 推薦システムにおいて大きな注目を集めているが, どのような状況で双曲面空間を考慮すべきかは明らかでない
- この研究では, 推薦システムのための双曲空間と双曲埋込みに関して包括的な分析を行なった
  - まず, 双曲空間とポアンカレ球モデルを紹介
  - 次に, 異なるモデル, データセット, および潜在空間の次元における双曲空間の性能に関して3つの仮説を提案
  - 最後にメトリック学習に基づく社会的推薦手法であるSocial Collaborative Metric Learning (SCML)と, その双曲空間版であるHyperbolic Social Collaborative Metric Learning (HSCML)を提案
- 推薦タスクの6つのベンチマークデータセットと6つのモデルを用いて仮説を実証的に検証


### Why Attentions May Not Be Interpretable?  [PDF](https://arxiv.org/abs/2006.05656)
#### Bing Bai (Tencent); Jian Liang (Alibaba Group); Guanhua Zhang (Tencent); Hao Li (Tencent Inc); Kun Bai (Tencent Inc); Fei Wang (Cornell University)
**イントロ**
- モデルの解釈はモデルがどのように意思決定を行うかを説明するものであり, 医療, セキュリティ, 刑事司法など意思決定プロセスの説明責任と透明性が重視される領域において得に重要である
- アテンション機構はモデルの解釈において重要な役割を果たしている
- しかし最近の研究では, アテンション機構で予測された特徴量の重要度が直感的な重要度と必ずしも相関していないことが示唆されている 
- 本論文はアテンション機構の解釈可能性を妨げている根本的な原因は組み合わせによる簡略化であると主張
  - アテンション結果はマスクと $$V$$の積であるため, マスク自体が $$V$$のハイライト部以外の余分な情報を含んでいる可能性がある


### Zero-shot Node Classification with Decomposed Graph Prototype Network  [PDF](https://arxiv.org/abs/2106.08022) [Site](https://zhengwang100.github.io/project/zero_shot_graph_embedding.html)
#### Zheng Wang (University of Macau); Jialong Wang (University of Macau); Yuchen Guo (Tsinghua University); Zhiguo Gong (University of Macau)
- ZGE (Zero-shot Graph Embedding)は, すべてのクラスについてのラベル付きデータがない (不均衡ラベル)場合に判別可能なグラフ埋め込みを学習するもの
  - ここでZero-shotは未知のクラスに属するノードを扱うこと



