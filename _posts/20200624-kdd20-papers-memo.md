---
layout: post
title: KDD 2020 Papers サーベイメモ
tags: [KDD2020]
---

## Links
[KDD 2020 Accepted Papers](https://www.kdd.org/kdd2020/accepted-papers)  
[KDD 2020 Proceedings](https://www.kdd.org/kdd2020/proceedings/)

---
## A causal look at statistical definitions of discrimination
### [PDF](https://dl.acm.org/doi/pdf/10.1145/3394486.3403130)
**イントロ**
- 心理テスト, 教育テストにおいてはフェアな分類器の基準として「予測の同等性 (predictive parity)」がスタンダードになっている
- 同様にerror rate balance, equalized oddsなどもフェアネスの基準として用いられる
- 本稿ではpredictive parityとerror rate balanceを因果の視点から分析する 
- 本研究ではフェアネスを考慮していない一般的な分類器は通常predictive parityの条件を満たさないことを示す
- 一方で一般的な分類器はerror rate balanceを満たしうる
- これらを証明するため, 本稿では分類器をデータ生成過程として理解し直し因果ダイアグラムとして表現する
  - 因果推論においては, データ生成過程についての仮定はobserved data causal diagramと呼ばれる因果ダイアグラムで表される
  - 機械学習の分類器の予測をデータ生成過程の出力として理解することでこの過程を因果ダイアグラムとして解釈し, prediction causal diagramと呼ぶ
- 因果ダイアグラムによって判断される独立性の基準を用いて以下を示す
  - (i) 出力がd分離の場合にデータ生成過程がerror rate balanceを達成できること <br>
  - (ii) グループによってベースレートが異なりかつデータが完全分離でない場合, predictive parityを達成できないこと 
- ちなみに(ii)の基準はデータの構造によらず成り立つ
- 人工データを用いて上記を実験的に検証した
- さらにCOMPASデータを分析し直し, predictive parityの欠如に関する証拠を挙げた

**提案手法**
- 特徴量をX, 出力をY, 差別に関連する変数 (属性など)をAとする
- predictive parityはPPVa = P(Yts=1|Ats=a,Yˆts=1)と定義することができる
- Mをモデル, Rを予測器とすると分類器のダイアグラムは図1のように描ける
- 特徴量Aを入れると図2のように描ける
- 図3はメジャーな分類器に対応する因果ダイアグラムのリスト
- predictive parityに関する証明
  - YtsとAtsが独立でないならPPV0 /= PPV1であることを図3の因果ダイアグラムのリスト各々について示す
  - Ytsは全ての因果ダイアグラムにおいてYtsをAtsからd分離しない
  - 従って(1)式より結果 (ii)が証明できる
- FPR (false positive rate)とFNR (false negative rate)に関する証明
  - Ytsはいくつかの因果ダイアグラムでYtsをAtsからd分離する
  - これらのダイアグラムに対応する分類器においては error rate balanceが満たされる

**実験**
- 人工データを使った実験を行い上記の結果を実例で説明する
  - YtsがAtsを\hat{Y}tsからd分離するようなダイアグラム (分類器)としないような分類器を二つ用意しそれらのダイアグラムに基づいて人工データを生成する
  - 生成した人工データに対して (i) Bayes classifierを学習し (ii) PPVなどの指標を計算し (iii) ベースレートの差を記録する
  - 図3を見ると, d分離するダイアグラム (Model 1)ではFPR1−FPR0が無視できるほど小さいのに対し, d分離しないダイアグラム (Model 2)ではそうなっていない
  - この結果は前章で導いた結果と一致する
- COMPASデータの再検証
  - COMPASデータは人種に関するpredictive parityが満たされている例として使われてきた
  - しかしこの前提は前章で導いた結果と矛盾する
  - 図8に各々の人種ごとのPPVaを示す
  - エラーバーがかぶっていないところを見るとこのデータはpredictive parityを満たしていない
  - 統計が足りていないのにも関わらずpredictive parityの検証をしてしまった可能性

---
## List-wise Fairness Criterion for Point Processes
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403246)
**イントロ**
- 種々のイベント系列は時間方法・空間方向のtriggering/clusteringパターンを示す
  - 大きな地震の後に震源地の近くで別の地震が起きる
  - 犯罪が起きやすい地域では近所で似た犯罪が繰り返される
- イベントレートを予測し起きやすさをランク付けすることで様々なシーンで役立てることができる
  - 犯罪が起きやすそうな地域でパトロールを強化するなど
- イベントのモデル化には点過程が用いられている
  - Hawkes過程は過去のイベントの影響が線形結合で今のイベントに効くという仮定を置いたもの
  - 時空間Hawkes過程はこれを時空間に拡張したもの
- これらのモデルは高精度なイベント予測が可能だが, 予測結果にバイアスがかかっている可能性がある
  - 例えばTwitterの位置・時間情報付きデータは洪水の予測に使われているが, 社会経済的地位が高い人々ほど災害時にTwitterを使う傾向があることが知られている
  - このようなデータでモデルを学習すると社会経済的地位によって結果にバイアスがかかる可能性がある
  - predictive policingにおいては犯罪のリスクが高い地域のみパトロールするとその地域で検挙数が増え, 
    それに応じてリスクの予測値が上がりさらに検挙数が増え...というフィードバックループにはまる 
- 先行研究ではランキングに関するフェアネスの尺度が複数提案されているが, フェアネスの指標や事後的にランキングしたリストに焦点を当てたもので
- 最近の研究では尤度に制限を課すことで属性間の平等を考慮した時空間の犯罪予測手法が提案されている
  - 警備配置が属性間で偏らないような制約を入れている
  - ランク付けされた地域の全ての場所でフェアネスが保障されているわけではない
- 本研究ではlist-wiseなフェアネスの基準を提案した
  - フェアネスの基準を目的関数に導入しフェアネスに配慮したランキング関数を提案した
- いくつかの時空間データを使って実験を行いlist-wiseなフェアネスの有用性を示した
- 実験では提案法のスケーラビリティについても議論した 

**提案手法**
- イベントのハザードレートによってランク付けされたgrid cellは不利なグループにより不利な結果になる恐れがある
  - ここでいう不利なグループは人種的マイノリティ, 社会経済地位などに相当する
- 既存のフェアネスの基準はリスト全体について平均した値についてフェアネスを判断している
- ランキングの各要素におけるフェアネスは補償されていない
- 表1の例だと, トップ10について合計した値についてはフェアネスが保たれているがトップ1, トップ3などに限定するとその限りではない
- ランク付けの正解度を測るDiscounted Cumulative Gain (DCG)のアイデアを用いる
- グループそれぞれに対しランキングごとに重み付けしたランクの合計値を計算する
  - グループのペアごとに合計値の差を取り目的関数のペナルティ項として追加する

**実験**
- Portlandの犯罪データ, Dallasの犯罪データ, Houstonの台風データを使用
- フェアネスの指標三つと予測精度の指標三つで評価
- 図1はフェアネスの指標に対する結果
  - 提案手法のフェアネスに関する制約により人種間の偏りが軽減されている
- 図2はフェアネスのペナルティを加える前後予測精度の変化
  - 精度はフェアネス項によって大きな影響を受けているが, PAIはある程度精度を保っている
- ここまで精度とフェアネスのトレードオフについて調査した
  - List-wiseのペナルティはList-sumのペナルティより精度の下がり方がましになる
- 図3では提案手法で予測したホットスポットトップ20を図示
  - トップ20のホットスポットのリストのうち, 5箇所がフェアネスのペナルティによって入れ替わったが, リスク予測はある程度当たっている

---
## Towards Automated Neural Interaction Discovering for Click-Through Rate Prediction
### [PDF]()
**イントロ**
- クリック率の予測はリアルタイム入札, ウェブ広告, 検索エンジンの最適化などの応用で重要 
- 既存手法はexplicit featureとexplicit featureの相互作用をMLPで学習するものが多い
- 最近の研究ではダイアモンド構造を持ったMLPがトライアングル構造のものよりも有効だという結果が出ている 
- ニューラルネットワークのアーキテクチャを最適化するNeural Architecture Search (NAS)が発展している
- 相互作用を発見するためのNASの利用にはいくつか課題がある
  - CVタスクにおける画像特徴量と違ってクリック率の予測に使う特徴量は異種で高次元でスパースなものとデンスなものが混じっている
  - また, 既存のクリック率予測においては非構造化された探索空間が用いられている
  - さらにクリック率予測モデルの訓練には数十億以上のデータが使われる
  - 構造の異なるクリック率予測モデルでも精度はそこまで変わらないという報告がある -> NASで細かいモデルの違いを区別したい
- AutoCTRというモデルを提案
  - ランク学習を使う
  - サンプリングとハッシュサイズの削減で探索スピードを上げた

**提案手法**
- 2段階の階層構造を持った探索空間を構築しそれらをDAGでつなぐ
  - 内側の探索空間はユニット数などのハイパラ, ブロック間のつながりは外側の探索空間で探索する
  - 図1のように複数のブロックとブロック同士をつなぐワイヤで構成する
- ブロックを構築する際は機能性と複雑性を考慮する
- これらの要請を満たす3つのモデル (MLP, DP, FM)をブロックとして用いる
- ブロック以外には入力の選択 (デンス/スパース, 両方), ブロック同士のつながり, 各ブロックのハイパラを探索する
- 4つの要素を組み合わせを表すベクトルを用意
- 探索器は進化的アルゴリズムとランク学習を組み合わせたもの

**実験**
- Criteo, Avazu, KDD Cupの3つのベンチマークデータを使用
- 図4は探索したモデルの数に対するloglossの減り方
  - AutoCTRは探索の効率で既存手法を上回る
- 表3では一つのデータで探索したベストなモデルを他の二つのデータに転用して精度を評価した
  - 転移学習の設定においても提案手法は良い精度
- 図6は探索で見つけたベストなモデル
  - ダイアモンド構造のネットワークが推定されている -> これは先行研究の分析結果と一致 

---
## A Data Driven Graph Generative Model for Temporal Interaction Networks
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403082)
**イントロ**
- グラフの生成は重要なタスク
- 伝統的なグラフ生成モデルは特定の構造を仮定したもの
- 最近は深層生成モデルが使われている
- しかしこれらの手法はstaticなネットワークのために設計されたもの
- 実際のネットワークは本質的にdynamicであり, 時刻情報付きのシステムログの集合として保存されている
- 時変ネットワークのモデル化には時刻情報を丸めてグラフのスナップショットとしてモデル化する手法が取られる
- この手法の欠点は適切な時間粒度が不確実なこと
- 粒度が細かすぎるとスナップショットの数が増え計算コストがかかる
- 粗すぎると時間に関する情報が失われる可能性がある
- 本研究では以下のリサーチクエスチョンに取り組む
  - (Q1) 時間情報付きのエッジの系列をそのままモデル化できるか?
  - (Q2) グラフの構造と時間的特徴を保持したend-to-endの深層学習モデルを構築できるか?
- TagGenという手法を提案する
  - 時間的・構造的特徴を入力データから取得するためのランダムウォークサンプリングを提案
  - その上にbi-level self-attentionメカニズムを載っけた
  - さらにネットワークのcontextを生成する (ノード・エッジの削除・追加を行う)スキームを構築した

**提案手法**
- 提案手法は4つのステージからなる
  1. Sampling ランダムウォークでグラフから系列を抽出
  2. Generation ノード・エッジの削除・追加に対応する操作を定義し, 人工的な系列を生成
  3. Discrimination 生成されたグラフが入力と似た構造になっていることを補償するため, discriminatorモデルを適用
  4. Assembling ここまでの操作で生成されたランダムウォーク系列から時刻ごとの相互作用の頻度 (エッジ数)に基づきグラフを構築する

**実験**
- 7つのネットワーク時系列データを使って実験
- 6つのグラフ測度を考慮し生成されたデータと入力データの差を各測度ごとにMAPEで比較
- 図7に6つのグラフ測度それぞれについての誤差をプロット
  - 提案手法は全てのデータ, 全ての測度で既存手法より小さい誤差
- 図8はBITCOINデータにおけるタイムステップごとの測度の変化をプロットし実測と比較したもの
  - 提案手法は実際のカーブにうまくフィットしている 
- SOデータを用いてデータ拡張の設定においてanomaly detectionとリンク予測の精度を評価
  - データ拡張の設定において比較手法を上回る精度 

---
## xGAIL: Explainable Generative Adversarial Imitation Learning for Explainable Human Decision Analysis
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403186)
**イントロ**
- 人は日々意志決定をしている (タクシー運転手が乗客を探す, 会社員が通勤ルートを選ぶ等)
- どのような要素が人の意思決定に影響しているか理解できれば様々な応用で役立てることができる
- 意思決定プロセスはマルコフ決定過程でモデル化することができる
  - 人々の意思決定プロセスは決定の系列として与えられ, 報酬を最大化するように学習される
- 先行研究では報酬を最大化するため逆強化学習や模倣学習が用いられている
  - GAILを拡張してタクシー運転手間で知識の転用を行う手法など
- 逆強化学習やは報酬関数が線形 -> 人手での特徴量抽出が必要になる 
- GAILは高次元の特徴量を考慮できるが説明性が低い
- (i) 人の意思決定を模倣するような意思決定過程 (ii) 人の意思決定に関する知識 を学習する手法を提案 

---
## Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks 
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403118)
**イントロ**
- センサーの広がりによって気温, 価格, 交通速度, 電気利用料など様々な変化が記録できるようになっている
- 複数のドメインで取得された時系列は複数の時系列として表すことができる
- これらは互いに関連している
- 多変量時系列モデルは変数間の依存性を仮定している
  - 例えばVARやGPは変数間の関係に線形性を仮定している
  - LSTNetやTPA-LSTMなど深層学習ベースの手法は変数同士のペアワイズな関係を明示的にモデル化することができない -> 説明性が低い
- 多変量時系列をグラフという観点から見直す
  - 変数=ノード, 変数間の関係=隠れたエッジ
- 時空間GCNを適用したいが, いくつか課題がある
  1. グラフ構造が未知
  2. もし既知だとしてもそれが最適でないという発想がない (学習しない)
- 課題 iに対しては新しいグラフ学習レイヤーを提案する
- グラフ構造を含めた全パラメータ学習をできるフレームワークを構築することで課題 iiに対応する

**提案手法**
- 提案手法はgraph learning layer, mつのgraph convolutionモジュール, mつのtemporal convolutionモジュールからなる
- graph learning layerでは時系列間の関係を表す隣接行列を学習する
  - コスト削減のためサンプリング手法を使い, ノードのサブ集合間の関係のみを考慮する
  - ノードのembeddingを学習しそれらの非線形変換の内積で隣接行列をモデル化 
  - 隣接行列の値のうちトップ k以外は0にする

**実験**
- マルチステップ予測とシングルステップ予測の二つのタスクについて四つのベンチマークデータを使って精度評価
- 既存手法はシングルステップ予測にはAR, GP, LSTNet等を, マルチステップ予測にはGCNベースの手法を中心に用いる
- 図6にcase studyの結果
  - 図6aは隣接行列をfixした時の時系列 (55番目のノードとその近隣ノード3つ), 図6bは隣接行列を学習した結果
  - 図6cはそれらのノードの場所を地図上に可視化したもの (緑が学習で推定した近隣ノード, 黄色が事前に定義された近隣ノード)
  - 図6cを見ると事前に定義した近隣ノードは55番目のノードに地理的に近い場所にあるのに対し学習された近隣ノードは地理的には遠いが同じ道路上にある
  - そのため図6aでは4つのノードの時系列が同時に変化しているのに対し図6bでは時差付きの相関が見られる
  - 学習した図6bの方が実際の異常時の道路状況をよく捉えている

---
## Heidegger: Interpretable Temporal Causal Discovery 
### [PDF]()
**イントロ**
- なぜ一部の人は歳を取ると認知能力が下がるのか? 何が原因なのか?
- このような因果関係を見つけることは認知の低下を予防するための介入を行う上で役に立つ
- 機械学習技術は因果の探索においては未発展
  - ほとんどの手法が単なる相関の分析にフォーカスしている
- ゴールドスタンダードはランダム化比較試験
  - コスト, 倫理, 技術の問題がある
- 観測データから因果を見つける手法も提案されている
- 生物学・化学における因果探索においては変数が時間によって大きく変化する
- 時間を考慮した因果探索を行う際は自己相関, 影響の遅れ, 潜在因子の影響, サンプリングの偏り, 一時的な介入, 計算コストを考慮する必要がある
- グレンジャー因果は時系列間の相関を評価するための先駆的な手法
  - しかしスパース性, 潜在因子, 非線形性, 多次元の関係性には対処できない
  - 最大の欠点は因果の広い捉え方にある (予測に効く変数=因果関係があるとは限らない)
- もう一つのアプローチは構造学習を適用するもの
  - 変数の数とともに計算量が増加する
- 既存手法の最大の欠点は因果を限られた意味で使っていること
  - ある変数が変化したら出力が変化するか否かのみを学習結果として出す
  - 変数が従う時間変化パターンは可視化できない
- 提案手法はグラフベース探索で効率性を, 準実験的研究 (QED)で柔軟性を担保

**提案手法**
- 因果関係をグラフで表す (エッジ=因果関係)
- 探索空間においてQEDを用いて最適なグラフを探す
  - 対照群と処理群を因果プロファイルとコントロールプロファイルに基づいて選ぶ
  - 選択した群をブロックに分ける
  - ペアごとに検定を行い各群が有意に異なるかどうか判定する 

**実験**
- 因果関係の発見能力の評価にAC交流送電システムのデータを用いた
  - ノードの値=電力システムの電圧
  - 候補の変数はインダクタンスの電圧, 出力はコンデンサーの電圧
  - 図3aからわかる通り提案手法は高精度に因果を発見することができる 
- 探索の強さの評価にはcognitive health studyをデータとして用いた
  - ライフスタイルの変化が認知の低下に影響するかどうかは明らかになっていない
  - 4091人のライフスタイルに関する調査 (10年間, 60歳〜85歳, 実験開始時に認知症を患っていない) 
  - 図4は候補の変数同士で検定を行なった場合のp値
  - 赤い線はBenjamini-Hochbergを用いてFalse Discovery Rateを調整した結果
  - p値は均等に分布した長いtailを持つ
  - 提案手法は全体の24.8%の仮説のみを検証し最もありえそうな因果を発見することができた
  - 運動, スポーツクラブへの加入, 学習クラスへの加入が認知症の予防になるという仮説が見つかった

---
## Deep State-Space Generative Model For Correlated Time-to-Event Predictions
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403206)
**イントロ**
- Time-to-event予測はヘルスケアなどのドメインで重要
- 既存手法は柔軟なモデル化手法, 共変量間の非線形な関係を捉えるものなど多数
- ただしそのほとんどは一つのイベントを予測するもので, 複数種類のイベントの相関を考慮できない
  - 例えばヘルスケアにおいては単一の臓器の異常だけでなく複数の臓器の異常の組み合わせが死につながるということがある
  - ある臓器の機能障害が他の臓器の異常につながる場合もある
- このように死に至るまでの時間は他の種類のイベントの複合的な要因に依る
- 複数種類のイベント間の依存関係を理解することは予測を高精度化するだけでなく適切な介入プランを考える上で役に立つ
- しかし複数種類のイベント間の相関の発見は未だオープンクエスチョン
- 観測から隠れた患者の状態を捉え医療イベント間の相関を見つける
- 深層状態空間生成モデルを提案
  - 複数種類のイベントを同時に予測 (例: 死亡リスクと臓器の異常リスク)

**提案手法**
- 潜在状態の変化を表す変数 ztを導入
  - 前の時刻の潜在状態と時刻 tにおける介入の影響で時刻 tにおける潜在状態が決まりそれに基づいて観測 (血圧などのバイタルサイン) xtが決まる
- ハザードレート λを潜在状態 ztに線形関数, ニューラルネットなどの関数をかませたものでモデル化
- 時刻 tにおける離散ハザードレートを S(t)と表記

**実験**
- MIMICデータを使用
- C-indexとAUPRCの二つの指標を用いて評価
- 図5はハザードレートと観測された死亡時刻 (円のマーカー)と打ち切り時刻(クロスマーカー) 
  - 観測イベントがある場合 (左の3列)はハザードレートが高く, 打ち切りデータ (右の3列)はハザードレートが低く推定されている
  - レートは150時間ぐらいでサチっている (新しい入力がないと自然にサチる)
- 図6はハザードレートと各種イベントの発生時刻
  - ハザードレートがゆるやかなイベントは遅めの時刻にイベントが発生し, ピーキーなものは早めにイベントが発生する
  - また, 死亡率のハザードレートは臓器異常と強く相関していることがわかる
- 表3が各種イベントの予測精度
  - 提案手法 (DSSM)は全ての指標で既存手法を上回る精度
  - 特に短期予測のAUC-ROCとAPで大きな改善

---
## Semantic Search in Millions of Equations
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403056)
**イントロ**
- 関連論文の調査を行うための検索エンジンが必要
- 検索は文章や単語に基づくものが主
  - 技術用語は分野によって違う意味を持つことがある, 逆に違う単語でも分野によって同じ意味を持つことがある
  - 例えばBayes’ lawという単語は天体物理学では情報フィールド理論として知られている
  - 物理の知識がなくてもベイズの法則を思い浮かべることができる
  - 別の例では, イジングモデルは物理の論文ではFerromagnetismus, 初期はBoltzmann machineと呼ばれていた
  - イジングモデルの最初の論文はドイツ語, イェンセンの不等式の論文はフランス語
  - 一方数式は簡単に理解できる
  - 物理や情報系の論文検索には数式を使うべき
　- 数式同士の関連度を判断するため, ノーテーションの違いと数式の一部同士のマッチングを取る必要がある
- 提案手法では意味的な関連性を学習するためGCNを使う
- タスクを二つ設定
  - コンテクストの類似度に基づいた教師なし学習
  - マスクされた言語モデルにインスパイアされた自己教師あり
- arXivの90万の論文から28.9億の数式を抽出し数式をone-hot表現の特徴量を用いたグラフとして表現した
- 評価にはアノテーション付きのデータを使った

**提案手法**
- arXivの90万の論文から'equation', 'align'などLatexの数式環境を抜き出す (インラインは無視)
- Katexライブラリを使ってLaTeXの数式をXMLベースのMathML表現にコンパイル
- さらにcitation関係を抽出するため付録のarXiv-idを用いた
- MathMLをグラフに変換
  - グラフの葉ノードは数字, 括弧, ギリシャ文字などのテキスト, 
  - XML構造を木と見做しタグと文字に基づいて特徴量を抽出する
  - 特徴量は256次元のone-hot表現
    - 最初の32次元がタグの種類, 次の32次元が属性 (太字など), 最後の192次元は頻出文字 (図2)
    - 頻出でない文字と属性にはそれぞれそれ用のsymbolを用意
- 構築したグラフをGCNにつっこむ
- 類似度の定義
  - 同じ論文に出てくる数式, citation元とcitation先の論文に出てくる数式は意味的に似ていると見なす
  - さらに同じ論文, 同じ章に出てくる数式を区別する
- Triplet lossに基づいてGCNのパラメータを学習
  - (ステップ1) ランダムに論文をサンプリングし選んだ論文からさらに数式をサンプル (ステップ2) 同じ章, 同じ論文, 参照論文から数式をサンプル を繰り返してポジティブなサンプルを生成
  - (ステップ1)に加え (ステップ2)でランダムに論文をサンプリングし選んだ論文からさらに数式をサンプルすることでネガティブなサンプルを生成
  - 上記で生成したネガティブ/ポジティブなサンプルを用いてTriplet lossを計算
- 上記を拡張してもう一つのタスクを設定
  - 数式中のsymbolの一部だけ隠して学習し隠していた部分を再構築する
  - BERTで有名になったマスクされた言語モデルと似たタスク
  - 類似度タスクにこのタスクを追加することで文脈情報だけでなく生の入力symbolの情報を保存できる

**実験**
- まず機械学習分野のサブセットで手法を検証
  - 表1にRanking scoreの評価結果
  - 既存手法のBitmap CNNをわずかに下回る精度 <- 既存手法ではテストデータに同じ論文が含まれるためフェアな比較ではない
- 次に全てのデータを使って実験 (表2)
  - 提案手法は全てのデータを使って学習し機械学習分野の論文で評価
- 図4, 5にイントロの例に対応する定性評価を図示
  - 図4ではBayes’ lawの別の表現が見つかっている
  - 図5ではIsing ModelsとBoltzmann Machineの両方に関連したほぼ同等の数式が見つかった
  

---
## Identifying Sepsis Subphenotypes via Time-Aware Multi-Modal Auto-Encoder
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403129)
**イントロ**
- 敗血症 (感染症に起因する生命を脅かすような臓器障害)は死因の半数を占めている
- 介入に対する反応が個人で違うため敗血症の患者の扱いは難しい
- subphenotypeの同定が重要
- 図1は電子健康記録の例
  - 属性, 診断, バイタルサインの系列などからなる
- 既存手法は重要な変数を集約しそれに基づいて患者を分類
- これらの手法は (i) 時間性を無視している (ii) 欠損値に対処できない という課題がある
- 提案手法は Time-Aware Multi-modal auto-Encoder (TAME)でまず欠損を埋める
- その後dynamic time wrapping (DTW)で患者同士の時間的類似度を測る
- 最後にweighted k-meansで患者を分類する
- DACMIとMIMIC-IIIという二つのパブリックデータで実験
- 欠損値の補完とk-meansによる分類で患者の分類精度を上げることができた

**提案手法**
- TAMEは複数種類の変数 (属性, 診断, バイタルサイン)を入力に取りベクトルを出力する
  - 欠損を表すマスク ctを導入
  - 変数と観測間のtime gapを三角関数を使ってembedding
  - それぞれの変数に関する特徴量が得られたらconcatinate -> max-pooling -> 双方向LSTM
  - time gapに関する特徴量を変換しattentionをかける
  - 観測との二乗誤差を最小化するパラメータを学習
- 欠損値補完が終わったらDTWで時系列間の関連性を判断しk-meansでクラスタリング

**実験**
- DACMIとMIMIC-IIIという二つのパブリックデータを使用
- 欠損値補完の精度をRMSEで評価
  - 表1, 2は二つのデータにおける各々の変数の補完精度 
- 図4は患者のクラスタリングの結果
  - 正解ラベルがないためラベルなしのデータに適用できる指標 (Calinski-Harabasz IndexとDavis-Bouldin Index)を使った 

---
## Mining Persistent Activity in Continually Evolving Networks
### [PDF](https://dl.acm.org/doi/10.1145/3394486.3403136)
**イントロ**
- ネットワークは時間とともに発展する
  - 交通網, コンピュータ間のネットワーク, ソーシャルネットワーク
- 既存手法は各パターンの数に注目し各々の頻度に基づいてネットワークの特性を理解しようとしている
  - しかしパターンが短期な場合, 特定の時間帯でカウント数が増大してしまい異常と見做されることがある
- 一方頻度は少ないが連続的かつ定期的に起こる重要な活動もある (ネットワークへの攻撃など)
- ネットワークの理解を深めるため, パターンの持続性 (どれくらい続くか)を考慮する必要がある
- 提案手法ではエッジの変更の系列をネットワークの変化とする
- temporal motifsのアイデアを拡張しnode間のactivityを記述するactivity snippetsを導入
- エッジのactivityを考慮することは様々な応用で重要
  - どの交通ルートが持続的に使われているか特定する, 怪しいノードまたはエッジを特定する等

**提案手法**
- 連続的に変化するネットワークを表すエッジのstreamが与えられた下で各々のactivity snippestの持続性 (持続時間, 頻度, 周期性)を推定
- まず持続性の測度の条件を整理
  - A1 非負 A2 時間幅→無限の極限をとると持続性も無限に発散する A3 発生時刻をずらしても測度に影響しない A4 時間幅を縮めると持続性が上がる
- 持続性の測度として幅, 頻度, 速度を定義し, それらの積を持続性の測度として定義
- 積を使って定義しておくと事前に設定した持続性の測度の条件を満たすことができる
- snippestのstramから持続性を保っているものを抽出するアルゴリズムを提案

**実験**
- 8つのネットワークデータを使って実験 (表2)
- 図4はバイクトリップデータに対する結果
  - 最も持続性の高いバイクトリップ (黒)が頻度も高い 
  - ボストンではMITの前の通りから最寄りの地下鉄駅までのルートからのトリップが最も持続性が高い <- 通勤ルートを反映
  - 図4(a)(b)どちらの図でもオレンジが新しくできたバイクステーションに対応している 
  - ボストンではMITの目の前に新しいバイクステーションができ, すぐに人気のステーションになった
- 図5はNYCのタクシーデータに対する結果
  - オレンジのバーストは台風に対応
  - ブルーは立地の都合上台風の影響を免れている or 近くに病院があり台風でもタクシー需要が保たれている地域のため持続性が高い
- 図6はStack overflowにおける二人のユーザ間のコミュニケーションに対する結果
  - activityは質問へのコメント, 回答へのコメント, 質問への回答の三種類ある
  - 質問へのコメントは図のオレンジ (バースト)に対応, 回答は比較的持続性がある
- 図7は異常検出の結果
  - 時刻 tにsnippest xが現れたら頻度と持続性を生成
  - その後異常検出手法を適用 (今回はRandom Cut Forestを使用)
  - 図7(a)はあるsubredditから別のsubredditへの参照に対する結果 
  - 特定のユーザが他のsubredditに出張して宣伝する規則的なパターンを異常として検出
  - 図7(b)のタクシー乗車データにおいては規則的におこる異常パターンとしてテストドライブを検出
- 表3に異常検知の精度を比較
　- Chicagoバイクトリップデータに人工的に生成した50のトリップを混ぜ, それらを検出するタスク
  - 提案手法は既存手法に比べ, 連続性のある異常を精度よく検出できている
- この他にスケーラビリティも評価

--- 
## Kernel Assisted Learning for Personalized Dose Finding 
### [PDF](https://dl.acm.org/doi/pdf/10.1145/3394486.3403048)
**イントロ**
- 薬の用量の最適化に取り組む
- 患者をランダムに選んで薬を処方し経過を見るというアプローチが典型的
- しかし最適な用量は患者の状態によって異なる
- 最近パーソナライズされた治療の推薦手法が注目されている
  - 適用できる有限の治療法の中から患者個人の情報に基づいて最適な治療を選ぶ
- 所望の出力を最大化する治療法を学習する手法が複数提案されている
  - Q-learning, A-learningを含む
- しかしこれらの手法は治療段階が多数ある場合に適用できない
  - 例えば血栓を防ぐワルファリンは適量が患者によって10倍程度違うため, 用量の推定が難しい
  - 処方量を間違えると大量出血を起こす
- このような場合, 個人の用量は状態に応じて安全な処方量の範囲内で推薦される
- 既存研究の拡張の方向性の一つとして連続の処方量に扱えるように処方量を離散化したもの, 患者を分類し各々に一つの処方ルールをあてはめたもの, 二値の出力を当てるものから順序を当てられるよう拡張したもの などがある
- しかし処方量の変化に敏感な場合, 粗い離散化では適切な推定ができない場合がある
- 一方離散化幅を細かくすると一つ一つのグループに振り分けられるデータが少なくなりオーバーフィッティングを招く
- Q-learningを拡張した手法も提案されているが, これは処方量と共変量の関係を特定の関数形でモデル化したもの -> misspecificationの恐れあり, かつ推定した処方量が安全な処方量の範囲内にあることを補償しない
- 他に個人の報酬を重みとして重み付け回帰を用いる手法もある
- この手法はmisspecificationに対してロバストで計算上の利点もある (non-convex loss)が推定された処方法に対する統計推論ができない
- 本研究ではkernel assisted learning法を提案
- 提案法は直接探索法と見做せる
  - まずkernel based estimatorでvalue functionを推定
  - その後予め定義された用法の中から個人の処方法を探す

**提案手法**
- i番目の患者の共変量 Xi, 適用された用量 Ai, 出力 (容態など) Yiの系列が観測されている
- 個人に最適化された処方法を 𝜋(𝑋) とおく
- 価値関数 𝑉(𝜋) =𝐸[𝑌∗{𝜋(𝑋)}]を最大化する 𝜋を見つける
- 価値関数をデータから推定するためいくつか仮定を置くと𝑉(𝜋)はA, Xが与えられた下でのYの期待値で書き換えられる
- まずはカーネルに基づく推定法を使って 𝑉(𝜋)を推定する
- 処方法を関数として定義しておく (今回はxの線形変換にリンク関数をかませたものを使用)
- リンク関数をかませることで安全な処方量の範囲内に収まることを補償
- あとは価値関数を最大化するβを推定する 
- 最適化 (βの推定)にはRパッケージのoptimr()を使用
- 積分は離散近似


---
## A Framework for Recommending Accurate and Diverse Items Using Bayesian Graph Convolutional Neural Networks 
### [PDF](https://dl.acm.org/doi/pdf/10.1145/3394486.3403254)
**イントロ**
- オンラインショッピング, ビデオ視聴, ニュース行動などオンライン上の消費行動がポピュラーに
- このような消費行動を予測するための推薦手法は userとitemのembedding, それらの間の非線形な関係を捉えるものが提案されている
- しかし, 既存の推薦手法には三つの大きな課題がある
  - スパース性: ユーザとアイテムの相互作用が少ない場合, よい表現を学習できない
  - 不確実性: 既存手法はデータを不確実性がないものとして扱っている
  - 多様性: 既存のtop-N推薦手法はtop-Nのアイテムそれぞれのみにフォーカスしており, トップN個のアイテムの多様性を見過ごしている
- GCNはスパースなデータやコールドスタート問題に対処できるということが知られている
- ただし不確実性や多様性を考慮することはできない
- Bayesian Graph Neural Networks (BGNNs)に基づきnode-copyingを用いた新たな手法を提案
- node-copyingモデルは観測グラフに似ているが十分な多様性を含む
- 提案手法はスケーラブルで不確実性に対処できる


---
## A Geometric Approach to Time Series Chains Improves Robustness 
### [PDF]()

---
## AutoGrow: Automatic Layer Growing in Deep Convolutional Networks 
### [PDF](https://arxiv.org/pdf/1906.02909)

---
## Catalysis Clustering With GAN By Incorporating Domain Knowledge 
### [PDF](https://dl.acm.org/doi/pdf/10.1145/3394486.3403187)

---
## Correlation Networks for Extreme Multi-label Text Classification 
### [PDF]()

---
## Curb-GAN: Conditional Urban Traffic Estimation through Spatio-Temporal Generative Adversarial Networks
### [PDF]()

---
## Deep Exogenous and Endogenous Influence Combination for Social Chatter Intensity Prediction 
### [PDF](https://arxiv.org/abs/2006.07812)

---
## Deep Learning of High-Order Interactions for Protein Interface Prediction
### [PDF]()

---
## HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records 
### [PDF]()

---
## INPREM: An Interpretable and Trustworthy Predictive Model for Healthcare 
### [PDF]()

---
## Local Motif Clustering on Time-Evolving Graphs 
### [PDF]()

