---
layout: post
title: "CAUSE: Learning Granger Causality from Event Sequences using Attribution Methods"
tags: [ICML20]
---

<!--more-->

[PDF](https://arxiv.org/abs/2002.07906)

[Video](https://icml.cc/virtual/2020/poster/5855)

**タスク**
- Given: 複数種類のイベント系列
  - イベントの発生時刻と種類を表すラベルの組からなる
  - 電子医療記録, オンラインでのユーザ行動, 金融取引等のデータを含む
- Output: イベントの種類の間の因果関係 (グレンジャー因果)
 
**既存手法**
- 多変量点過程, 特にHawkes過程が用いられる
  - 説明性が高い, グレンジャー因果を直接モデル化できるという利点
  - 柔軟性が低い, 自己励起以外はモデル化できないという欠点
- ニューラルネットを用いた点過程
  - 説明性が高い, 未来のイベントを予測できる
  - 解釈性が低い, グレンジャー因果を明らかにできない

**提案手法** 
- TrainingステージとPost-trainingステージからなる
  - Trainingステージはニューラルネットを用いた点過程, Post-trainingステージではattribution methodを使用
  - これにより柔軟性と説明性を兼ね備えた
- Trainingステージ
  - 提案手法のインテンシティをHawkes過程と同様カーネル関数の重み付け和でモデル化
  - 各時刻 $$t_i$$までの系列をGRUでエンコードしカーネル関数の重みパラメータとして使用
- Post-trainingステージ
  - Attribution methodはニューラルネット等のブラックボックス関数について入力 (画像など)の重要度を出力する手法
  - 重要度を知りたい入力 $${\bf x}$$とベースラインとなる仮の入力 $$\overline{\bf x}$$ (無地の画像など)を比較
  - イベントデータに適用する場合, 以下が問題になる
    1. ブラックボックス関数が時間に依存している
    2. どのようなベースラインを使えばいいか? 
  - インテンシティを時刻 $$t$$について積分することで時間依存の項を消す
  - ベースラインとしてはシンプルに $${\bf 0}$$を使用
  - Attribution methodとしてIntegrated Gradientを使用

**実験**
- 自己励起, 抑制作用を仮定したシュミレーションデータ2つと実データ2つを使用
- 表1ではグレンジャー因果の推定結果をAUCとKendall's $$\tau$$で評価
  - 提案手法は全てのデータで概ね良い結果
  - 提案手法以外のHawkes過程ベースの手法は自己励起以外のデータで低い精度
  - ニューラルネットを使った点過程手法は全てのデータで低い精度 $$\rightarrow$$ アテンションでグレンジャー因果を推定するのは難しい?
- 図2では推定したIPTVデータに対して推定したグレンジャー因果を可視化
  - 対角成分を見ると同じカテゴリの動画に強い因果関係があるのがわかる
  - 経済, 教育, 法律, 軍隊とニュースにも因果関係
  - 教育とエンターテイメントに負の因果



